import numpy as np
import pandas as pd
import streamlit as st
from sklearn import metrics, tree
from sklearn.datasets import make_classification
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (accuracy_score, classification_report,
                             cohen_kappa_score, confusion_matrix,
                             precision_score, recall_score)
from sklearn.model_selection import train_test_splitfrom sklearn.metrics import plot_confusion_matrix, plot_roc_curve, plot_precision_recall_curve

from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.svm import SVC, LinearSVC

df1 = pd.read_csv("datasetfeaturescategories.csv", encoding='utf8')
df2 = pd.read_csv("drebin215dataset5560malware9476benign.csv")

pd.set_option('display.max_columns', None)
df1.head()
df1.columns = map(str.lower, df1.columns)
for column in df1.columns.tolist():
    print(column)
classes, count = np.unique(df2['class'], return_counts=True)
lbl_enc = LabelEncoder()
df2 = df2.replace(classes, lbl_enc.fit_transform(classes))

# Dataset contains special characters like ''?' and 'S'. Set them to NaN and use dropna() to remove them
df2 = df2.replace('[?,S]', np.NaN, regex=True)
# print("Total missing values : ",sum(list(df2.isna().sum())))
df2.dropna(inplace=True)
for c in df2.columns:
    df2[c] = pd.to_numeric(df2[c])
df2

train_x, test_x, train_y, test_y = train_test_split(df2[df2.columns[:len(
    df2.columns)-1]].to_numpy(), df2[df2.columns[-1]].to_numpy(), test_size=0.2, shuffle=True)


data_num_corr = df2.corr()['class'][:-1]
golden_features_list_1 = data_num_corr[abs(
    data_num_corr) > 0.5].sort_values(ascending=False)
golden_features_list_1
state = st.number_input('Random State', key='state',
                        min_value=5, max_value=100, value=45, step=5)
estimator = st.number_input(
    'Estimator', key='estimator', min_value=100, max_value=500, value=250, step=100)
debth = st.number_input('debth', key='debth', min_value=10,
                        max_value=100, value=50, step=10)

if st.button('RandomForest'):
    rdF = RandomForestClassifier(
        n_estimators=estimator, max_depth=debth, random_state=state)
    rdF.fit(train_x, train_y)
    pred = rdF.predict(test_x)
    cm = confusion_matrix(test_y, pred)

    accuracy = accuracy_score(test_y, pred).round(2)
    st.write("Random Forest Classifier")
    st.write("Accuracy Score: " + str(accuracy))
    st.write("Precision: ", precision_score(
        test_y, pred, labels=None).round(2))
    st.write("Recall: ", recall_score(test_y, pred, labels=None).round(2))
    st.write("cohen kappa score: ", cohen_kappa_score(test_y, pred))
    st.write("")
    st.subheader("ROC Curve")
    plot_roc_curve(rdF, test_x, test_y)
    st.pyplot()

range1 = st.number_input('Range1', key='range1',
                         min_value=3, max_value=100, value=3, step=3)
range2 = st.number_input('range2', key='range2',
                         min_value=15, max_value=100, value=15, step=5)
range3 = st.number_input('range3', key='range3',
                         min_value=3, max_value=100, value=3, step=3)

if st.button('KNeighborsClassifier'):
    for i in range(3, 15, 3):

        neigh = KNeighborsClassifier(n_neighbors=i)
        neigh.fit(train_x, train_y)
        pred = neigh.predict(test_x)
        accuracy = accuracy_score(pred, test_y)
        st.write("k-neighbors evaluation".format(i))
        st.write("Accuracy: " + str(accuracy))
        st.write(classification_report(pred, test_y, labels=None))
        st.write("")
